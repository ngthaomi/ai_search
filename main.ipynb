{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c758cf4",
   "metadata": {
    "id": "8c758cf4",
    "papermill": {
     "duration": 0.02617,
     "end_time": "2025-07-09T14:04:47.529338",
     "exception": false,
     "start_time": "2025-07-09T14:04:47.503168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **AI Search with RefinedWeb Dataset and OLMo 2 Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfc934-f454-4547-822e-c400c561776f",
   "metadata": {
    "id": "fcdfc934-f454-4547-822e-c400c561776f",
    "papermill": {
     "duration": 0.020324,
     "end_time": "2025-07-09T14:04:47.571418",
     "exception": false,
     "start_time": "2025-07-09T14:04:47.551094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Table of Contents\n",
    "- [0. Setup](#0-setup)  \n",
    "- [1. Data Loading](#1-data-loading)  \n",
    "- [2. Data Exploration](#2-data-exploration)  \n",
    "- [3. Data Preprocessing](#3-data-preprocessing)  \n",
    "    - [3.1 Data Cleaning](#31-data-cleaning)   \n",
    "    - [3.2 Feature Engineering](#32-feature-engineering)  \n",
    "- [4. Brand Sentiment Analysis](#4-brand-sentiment-analysis)  \n",
    "    - [4.1 Lexicon-Based](#41-lexicon-based)  \n",
    "    - [4.2 Transformer-based](#42-transformer-based)\n",
    "- [5. Brand-Specific Analysis](#5-brand-specific-analysis)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcf565-b4d6-4ee3-b89d-c84c6eae06ef",
   "metadata": {
    "id": "66fcf565-b4d6-4ee3-b89d-c84c6eae06ef",
    "papermill": {
     "duration": 0.021188,
     "end_time": "2025-07-09T14:04:47.614145",
     "exception": false,
     "start_time": "2025-07-09T14:04:47.592957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "B5rtJ6INEdkP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-09T14:04:47.662713Z",
     "iopub.status.busy": "2025-07-09T14:04:47.662325Z",
     "iopub.status.idle": "2025-07-09T14:04:47.760082Z",
     "shell.execute_reply": "2025-07-09T14:04:47.758847Z"
    },
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1752068821036,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "B5rtJ6INEdkP",
    "outputId": "7e586f8d-f0cb-480c-ccfd-04ac7f6931c3",
    "papermill": {
     "duration": 0.124593,
     "end_time": "2025-07-09T14:04:47.761546",
     "exception": true,
     "start_time": "2025-07-09T14:04:47.636953",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/hostname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;34m'Mounting drive is unsupported in this environment. Use PyDrive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34m' instead. See examples at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2."
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12BcqcadF8IR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752068821036,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "12BcqcadF8IR",
    "outputId": "bb38d286-7dc9-469d-b0f9-19b6ee065f09",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/content/drive/My Drive/Digitas'\n",
    "\n",
    "# Example: list all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55d557-6caf-4f8b-866e-4b955cdcc7a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20815,
     "status": "ok",
     "timestamp": 1752068841849,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "0f55d557-6caf-4f8b-866e-4b955cdcc7a4",
    "outputId": "f1d57833-df1d-45bc-ebe5-0511eb53965d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r \"/content/drive/My Drive/Digitas/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f76d1",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752068841851,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "319f76d1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import nltk\n",
    "import spacy\n",
    "import glob\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a1817-50a8-4971-ba8b-aa21a5dd4883",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1752068841861,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "b13a1817-50a8-4971-ba8b-aa21a5dd4883",
    "outputId": "88b940a1-c163-440a-b129-88da5071e69a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import size, col, udf, pandas_udf, PandasUDFType, arrays_zip, array_contains, substring, length, explode, first, avg, when, monotonically_increasing_id\n",
    "from pyspark.sql.functions import to_date, dayofmonth, month, year\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, FloatType, BooleanType, ArrayType, StructType, StructField\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from huggingface_hub import HfApi\n",
    "# from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from collections import defaultdict\n",
    "from emoji import demojize\n",
    "from urllib.parse import urlparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datasets import load_dataset\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cefc4-be05-4082-81ae-80cbd6ec1f6c",
   "metadata": {
    "id": "324cefc4-be05-4082-81ae-80cbd6ec1f6c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 1. Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95441793-6047-4a4b-acd7-39027884dba6",
   "metadata": {
    "id": "95441793-6047-4a4b-acd7-39027884dba6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Generating Paths Files\n",
    "This section of the code generates `refinedweb_paths.txt` with URLs to Parquet files for each dataset. If the files already exist, the code verifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967d710-2cb7-4e52-abd9-74fe81ab0a70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2335,
     "status": "ok",
     "timestamp": 1752068844197,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "4967d710-2cb7-4e52-abd9-74fe81ab0a70",
    "outputId": "d7046424-61c9-4c19-d80b-09d02eb36c94",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_paths_file(dataset_id, output_file, directory_prefix=None):\n",
    "    api = HfApi()\n",
    "\n",
    "    # List all files in the dataset repository\n",
    "    files = api.list_repo_files(repo_id=dataset_id, repo_type=\"dataset\")\n",
    "\n",
    "    # Filter for Parquet files\n",
    "    parquet_urls = [\n",
    "        f\"https://huggingface.co/datasets/{dataset_id}/resolve/main/{f}\"\n",
    "        for f in files if f.endswith(\".parquet\") and (directory_prefix is None or f.startswith(directory_prefix))\n",
    "    ]\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    # If file exists, verify contents\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"{output_file} already exists. Verifying contents...\")\n",
    "        with open(output_file, \"r\") as f:\n",
    "            existing_urls = set(line.strip() for line in f if line.strip())\n",
    "        if set(parquet_urls).issubset(existing_urls):\n",
    "            print(f\"{output_file} is valid with {len(existing_urls)} URLs.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Updating {output_file} with new URLs...\")\n",
    "    # Save URLs to file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for url in parquet_urls:\n",
    "            f.write(url + \"\\n\")\n",
    "    print(f\"Saved {len(parquet_urls)} URLs to {output_file}\")\n",
    "\n",
    "\n",
    "# Generate paths for RefinedWeb\n",
    "generate_paths_file(\"tiiuae/falcon-refinedweb\", \"data/refinedweb/refinedweb_paths.txt\", directory_prefix=\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae0a6f7-4dae-4faf-bfd7-f891fc51001f",
   "metadata": {
    "id": "5ae0a6f7-4dae-4faf-bfd7-f891fc51001f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1.2 Download Dataset\n",
    "The following code runs the `download_parquet.sh` script to download Parquet files for both datasets. The files will be saved to `data/refinedweb/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d348f-1010-46ef-807e-820b4e083583",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752068844200,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "643d348f-1010-46ef-807e-820b4e083583",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_dataset(dataset_name, paths_file):\n",
    "    paths_file = os.path.abspath(paths_file)\n",
    "    if not os.path.exists(paths_file):\n",
    "        print(f\"Error: {paths_file} does not exist. Skipping download for {dataset_name}.\")\n",
    "        return False\n",
    "    if not os.path.getsize(paths_file) > 0:\n",
    "        print(f\"Error: {paths_file} is empty. Skipping download for {dataset_name}.\")\n",
    "        return False\n",
    "    print(f\"Downloading {dataset_name} dataset...\")\n",
    "    try:\n",
    "        log_file = f\"data/{dataset_name}/download.log\"\n",
    "        os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "        with open(log_file, \"w\") as f:\n",
    "            process = subprocess.Popen(\n",
    "                [\"bash\", \"download_parquet.sh\", dataset_name, paths_file],\n",
    "                stdout=f,\n",
    "                stderr=f,\n",
    "                text=True\n",
    "            )\n",
    "            process.wait(timeout=3600)  # 1 hour timeout\n",
    "        with open(log_file, \"r\") as f:\n",
    "            print(f.read())\n",
    "        return process.returncode == 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error running download script for {dataset_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# # Downloads RefinedWeb parquet files\n",
    "# download_dataset(\"refinedweb\", \"data/refinedweb/refinedweb_paths.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9cbf27-4ab4-4d40-9905-37679a809457",
   "metadata": {
    "id": "9b9cbf27-4ab4-4d40-9905-37679a809457",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We will consequently verify the downloaded Parquet files to ensure they are accessible and readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f344fc1-f7da-492c-a698-ac0d436c1ae4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752068844205,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "7f344fc1-f7da-492c-a698-ac0d436c1ae4",
    "outputId": "32ee327d-8aad-48ce-9536-6caa341589d4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verify_parquet_files(directory):\n",
    "    # Find all Parquet files in the directory\n",
    "    parquet_files = glob.glob(f\"{directory}/*.parquet\")\n",
    "    print(f\"Number of Parquet files in {directory}: {len(parquet_files)}\")\n",
    "\n",
    "    if parquet_files:\n",
    "        # Try reading the first Parquet file as a sample using Spark\n",
    "        try:\n",
    "            # Read the first Parquet file into a Spark DataFrame\n",
    "            df_sample = spark.read.parquet(parquet_files[0])\n",
    "            print(f\"Number of rows per Parquet file: {df_sample.count()}\")\n",
    "\n",
    "            # Check for null values in all columns\n",
    "            print(\"\\nNull value counts per column:\")\n",
    "            from pyspark.sql.functions import col\n",
    "            for column in df_sample.columns:\n",
    "                null_count = df_sample.filter(col(column).isNull()).count()\n",
    "                print(f\"{column}: {null_count} nulls\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {parquet_files[0]}: {e}\")\n",
    "    else:\n",
    "        print(f\"No Parquet files found in {directory}\")\n",
    "\n",
    "verify_parquet_files(\"data/refinedweb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb38b5b-e84c-4cc3-ab27-8d66a0eed25e",
   "metadata": {
    "id": "edb38b5b-e84c-4cc3-ab27-8d66a0eed25e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1.3 Load and Filter Documents with Brand Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b099f94-a495-4232-80f7-467eb105be7f",
   "metadata": {
    "id": "5b099f94-a495-4232-80f7-467eb105be7f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "PySpark is utilised to process the large-scale dataset. The Spark Session was initialised below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bee1c8-3212-4355-8628-2fe4a9fb1251",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752068844208,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "72bee1c8-3212-4355-8628-2fe4a9fb1251",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AI Search Pipeline\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# For more detailed logging\n",
    "# sc = spark.sparkContext\n",
    "# sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53af7a-6c6e-457e-957a-ce729303e28f",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752068844225,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "2a53af7a-6c6e-457e-957a-ce729303e28f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "def load_and_filter_data(input_dir, output_file):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    # Connect to DuckDB\n",
    "    con = duckdb.connect()\n",
    "\n",
    "    # Create filtered table\n",
    "    brands = [\"HSBC\", \"Barclays\", \"Lloyds\", \"NatWest\"]\n",
    "    brand_conditions = ' AND '.join([f\"LOWER(content) LIKE '%{brand.lower()}%'\" for brand in brands])  # All brands must be mentioned\n",
    "    query = f\"\"\"\n",
    "        CREATE OR REPLACE TABLE filtered_brands AS\n",
    "        SELECT *\n",
    "        FROM '{os.path.join(input_dir, \"*.parquet\")}'\n",
    "        WHERE {brand_conditions}\n",
    "    \"\"\"\n",
    "    con.execute(query)\n",
    "\n",
    "    # Export to Parquet\n",
    "    con.execute(f\"\"\"\n",
    "        COPY filtered_brands TO '{output_file}' (FORMAT PARQUET)\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"Filtered + Exported to {output_file}\")\n",
    "\n",
    "    # Close the connection\n",
    "    con.close()\n",
    "\n",
    "#load_and_filter_data(\"data/refinedweb\", \"data/filtered_data/brands_articles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1be1a-a5f4-4c75-a152-87b65daf2e4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1752068844924,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "11f1be1a-a5f4-4c75-a152-87b65daf2e4c",
    "outputId": "c06a90c3-2e61-45e7-8d90-10072f8788b0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/content/drive/My Drive/Digitas/data/filtered_data/brands_articles.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe512e55-0a75-4062-8a31-d470ccf88562",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1752068845405,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "fe512e55-0a75-4062-8a31-d470ccf88562",
    "outputId": "8804d5b9-0df8-4fe7-e595-4187866e2f3a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of documents mentioning all 4 brands together: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf5523-4530-43bf-81c8-2816dcbc3b85",
   "metadata": {
    "id": "9daf5523-4530-43bf-81c8-2816dcbc3b85",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2. Data Pre-processing\n",
    "\n",
    "This segment cleans and transforms the raw dataset to make it suitable for sentiment analysis, removing noise and extracting useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334f35e-1462-4c08-b3e4-4dc6081f69d7",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1752068845455,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "5334f35e-1462-4c08-b3e4-4dc6081f69d7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering for non-null/non-empty text\n",
    "df = df.filter(col(\"content\").isNotNull() & (col(\"content\") != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db2b07-e952-4a7f-bb7d-fe2fc9cbb6d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1752068846146,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "e1db2b07-e952-4a7f-bb7d-fe2fc9cbb6d0",
    "outputId": "883a9eaf-6231-4d5d-eeab-43b8f28dc19b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns\n",
    "df = df.drop(\"dump\", \"segment\", \"image_urls\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34717098-9445-45d7-9863-c9f69677bc38",
   "metadata": {
    "id": "34717098-9445-45d7-9863-c9f69677bc38",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.1 Filter Valid URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978e5b9-2b44-49f5-b98d-da185e652695",
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1752068846203,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "d978e5b9-2b44-49f5-b98d-da185e652695",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql.types import BooleanType\n",
    "import time\n",
    "\n",
    "# Function to check if a URL is valid\n",
    "def is_url_valid(url):\n",
    "    if not url:\n",
    "        return False\n",
    "    try:\n",
    "        # Send a HEAD request to minimize data transfer\n",
    "        response = requests.head(url, timeout=5, allow_redirects=True)\n",
    "        # Consider 200 as valid; you can adjust to include other codes (e.g., 301, 302)\n",
    "        return response.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        # Handle connection errors, timeouts, etc.\n",
    "        return False\n",
    "\n",
    "is_url_valid_udf = udf(is_url_valid, BooleanType())\n",
    "\n",
    "df = df.withColumn(\"is_url_valid\", is_url_valid_udf(col(\"url\")))\n",
    "# df.select(\"url\", \"is_url_valid\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df431251-66b7-4908-b359-6023c1264f86",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1752068846235,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "df431251-66b7-4908-b359-6023c1264f86",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter rows where URL is valid\n",
    "df = df.filter(col(\"is_url_valid\") == True)\n",
    "\n",
    "# print(f\"Number of documents with valid URLs mentioning all 4 brands: {df.count()}\")\n",
    "# df.select(\"url\", \"is_url_valid\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884908b-842c-40f3-9957-485b005b8d00",
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1752068846290,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "b884908b-842c-40f3-9957-485b005b8d00",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"is_url_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa9f2b-5134-4116-b5c7-aeb096949f5a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752068846291,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "89fa9f2b-5134-4116-b5c7-aeb096949f5a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Write the DataFrame as Parquet\n",
    "# output_path = \"data/filtered_data/valid_articles.parquet\"\n",
    "\n",
    "# df.write.mode(\"overwrite\").parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f763f5-34af-4083-8575-1262fcdff964",
   "metadata": {
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1752068846587,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "25f763f5-34af-4083-8575-1262fcdff964",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/content/drive/My Drive/Digitas/data/filtered_data/valid_articles.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718665e2-5cc1-4f93-aea4-2862796c27c3",
   "metadata": {
    "id": "718665e2-5cc1-4f93-aea4-2862796c27c3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Deduplication by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1d0b7-1ef6-4156-8456-607c23d28d95",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1752068846631,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "88f1d0b7-1ef6-4156-8456-607c23d28d95",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# URL date patterns\n",
    "url_date_patterns = [\n",
    "    r'/(\\d{4})/([a-z]{3})/(\\d{2})/',\n",
    "    r'/(\\d{4})/(\\d{2})/(\\d{2})/',\n",
    "    r'/(\\d{4})-(\\d{2})-(\\d{2})/',\n",
    "    r'/(\\d{4})\\.(\\d{2})\\.(\\d{2})/',\n",
    "    r'/(\\d{4})_(\\d{2})_(\\d{2})/',\n",
    "    r'(\\d{4})/(\\d{2})(\\d{2})/',\n",
    "    r'/(\\d{4})/(\\d{2})/',\n",
    "    r'/(\\d{4})-(\\d{2})/',\n",
    "    r'(\\d{4})[-_\\.](\\d{2})[-_\\.](\\d{2})',\n",
    "    r'post[-_]?(\\d{4})[-_](\\d{2})[-_](\\d{2})',\n",
    "    r'(\\d{8})',\n",
    "]\n",
    "\n",
    "month_abbrev_map = {\n",
    "    \"jan\": \"01\", \"feb\": \"02\", \"mar\": \"03\", \"apr\": \"04\",\n",
    "    \"may\": \"05\", \"jun\": \"06\", \"jul\": \"07\", \"aug\": \"08\",\n",
    "    \"sep\": \"09\", \"oct\": \"10\", \"nov\": \"11\", \"dec\": \"12\"\n",
    "}\n",
    "\n",
    "# TEXT patterns\n",
    "text_date_patterns = [\n",
    "    r'(?:Published|Posted|Updated|Created|First published|Last updated)[:\\s]*([A-Za-z]{3,9}[\\s\\-.,]?\\d{1,2}(?:st|nd|rd|th)?[\\s,]+(?:\\d{4}))',\n",
    "    r'(?:Published|Posted|Updated|Date|Created)[:\\s]*([\\d]{1,2}[\\s\\-/.][A-Za-z]{3,9}[\\s\\-/,]+[\\d]{4})',\n",
    "    r'(?:Published|Posted|Updated|Date)[:\\s]*([\\d]{4}[-/\\.][\\d]{1,2}[-/\\.][\\d]{1,2})',\n",
    "    r'([A-Za-z]{3,9}\\s\\d{4})',\n",
    "    r'(\\d{4}/\\d{2}/\\d{2})',\n",
    "    r'(\\d{2}[-/\\.]\\d{2}[-/\\.]\\d{4})',\n",
    "    r'(\\d{4}[-/\\.]\\d{2})',\n",
    "    r'/(\\d{4})/(\\d{1,2})/(\\d{1,2})/',\n",
    "    r'/(\\d{4})/(\\d{1,2})/'\n",
    "]\n",
    "\n",
    "# Combining extraction from 'url', revert to 'content' if date not found in url\n",
    "@F.udf(StringType())\n",
    "def extract_combined_date_udf(url, text):\n",
    "    def try_url_date(url_str):\n",
    "        if not url_str or not isinstance(url_str, str):\n",
    "            return None\n",
    "        if not re.search(r'https?://', url_str):\n",
    "            return None\n",
    "        for pattern in url_date_patterns:\n",
    "            match = re.search(pattern, url_str, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                try:\n",
    "                    parts = match.groups()\n",
    "                    if len(parts) == 3:\n",
    "                        year, month, day = parts\n",
    "                        if month.isalpha():\n",
    "                            month = month_abbrev_map.get(month.lower())\n",
    "                            if not month:\n",
    "                                continue\n",
    "                    elif len(parts) == 2:\n",
    "                        year, month = parts\n",
    "                        day = \"01\"\n",
    "                    elif len(parts) == 1:\n",
    "                        val = parts[0]\n",
    "                        if len(val) == 8:\n",
    "                            year, month, day = val[:4], val[4:6], val[6:]\n",
    "                        elif len(val) == 4:\n",
    "                            year, month, day = val, \"01\", \"01\"\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "                    y, m, d = int(year), int(month), int(day)\n",
    "                    if y < 1900 or y > datetime.now().year + 1:\n",
    "                        continue\n",
    "                    if m < 1 or m > 12:\n",
    "                        continue\n",
    "                    if d < 1 or d > 31:\n",
    "                        continue\n",
    "                    return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "                except:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def try_text_date(text_str):\n",
    "        if not text_str or not isinstance(text_str, str):\n",
    "            return None\n",
    "        text_str = re.sub(r'\\s+', ' ', text_str).strip()\n",
    "        current_year = datetime.now().year\n",
    "        probable_dates = []\n",
    "        for pattern in text_date_patterns:\n",
    "            matches = re.findall(pattern, text_str)\n",
    "            for match in matches:\n",
    "                raw = ' '.join(match) if isinstance(match, tuple) else match\n",
    "                try:\n",
    "                    parsed = parser.parse(raw, fuzzy=True)\n",
    "                    year = parsed.year\n",
    "                    if 1900 <= year <= current_year + 1:\n",
    "                        probable_dates.append(parsed.date().isoformat())\n",
    "                except:\n",
    "                    continue\n",
    "        return min(probable_dates) if probable_dates else None\n",
    "\n",
    "    # Try extracting from URL first\n",
    "    date_from_url = try_url_date(url)\n",
    "    if date_from_url:\n",
    "        return date_from_url\n",
    "\n",
    "    # If failed, try from text\n",
    "    return try_text_date(text)\n",
    "\n",
    "df = df.withColumn(\"published_date\", extract_combined_date_udf(F.col(\"url\"), F.col(\"content\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e98a7b-7c27-4ab5-a8dd-10ddd6ebb691",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4140,
     "status": "ok",
     "timestamp": 1752068850772,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "c1e98a7b-7c27-4ab5-a8dd-10ddd6ebb691",
    "outputId": "ff2756db-5614-429e-82ac-22ac05623452",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spark df\n",
    "# df.select(\"content\",\"url\", \"timestamp\", \"published_date\").show(truncate=False)\n",
    "\n",
    "# # Pandas df for readability\n",
    "pdf = df.select(\"content\", \"url\", \"timestamp\", \"published_date\").toPandas()\n",
    "# Truncate content\n",
    "pdf[\"content\"] = pdf[\"content\"].str[:50] + \"...\"\n",
    "\n",
    "# Display full URL\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(pdf.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcba3b-c7b5-4a53-804a-5266c5b9453c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8185,
     "status": "ok",
     "timestamp": 1752068858955,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "5cbcba3b-c7b5-4a53-804a-5266c5b9453c",
    "outputId": "e53d41e1-58f5-4437-d449-dcf6e31b9995",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropDuplicates([\"published_date\"])\n",
    "\n",
    "df.show(50)\n",
    "print(f\"Number of documents mentioning all 4 brands together after deduplication: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yty36auBbynY",
   "metadata": {
    "id": "Yty36auBbynY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2.3 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KOXvPCsebxJr",
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1752068931129,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "KOXvPCsebxJr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenisation - clean text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r'[\\n\\r]', ' ', text)     # removes newlines and carriage returns\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())     # removes punctuation and lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # whitespace\n",
    "    return text\n",
    "\n",
    "clean_udf = udf(clean_text, StringType())\n",
    "df = df.withColumn(\"clean_text\", clean_udf(col(\"content\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657a545-425e-467a-8706-cf509cb5c7e9",
   "metadata": {
    "id": "3657a545-425e-467a-8706-cf509cb5c7e9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3. Extracting Topics and Implicit Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "letNGq5jLFKy",
   "metadata": {
    "executionInfo": {
     "elapsed": 3766,
     "status": "ok",
     "timestamp": 1752068936265,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "letNGq5jLFKy",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "df = df.toPandas()\n",
    "\n",
    "# Stop Spark session to free up resources\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531f4e2-4a8e-4868-b59c-d1f3f3b0d81c",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752068949237,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "6531f4e2-4a8e-4868-b59c-d1f3f3b0d81c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "# Define topics\n",
    "topics = [\"Sustainability\", \"Financial Resilience and Performance\", \"Technological Innovation\", \"Customer Service\", \"Regulatory Compliance\", \"Governance and Leadership\", \"Other\"]\n",
    "\n",
    "# Replace with actual brand names from your analysis\n",
    "brands = [\"HSBC\", \"Barclays\", \"Lloyds\", \"NatWest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f60a46-dc2d-40b5-958b-a3c6c864d331",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5310,
     "status": "ok",
     "timestamp": 1752069352516,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "99f60a46-dc2d-40b5-958b-a3c6c864d331",
    "outputId": "a0c2888d-2099-4dc5-e9a4-7f5e40eca200",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize pipeline with device_map\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device_map=\"auto\"  # Automatically offloads to CPU if needed\n",
    ")\n",
    "\n",
    "def categorize_topic(text: str) -> str:\n",
    "    if not text or not isinstance(text, str):\n",
    "        return \"Other\"\n",
    "    text_preview = text[:1000]\n",
    "    # Check GPU memory and offload if near limit\n",
    "    if torch.cuda.memory_allocated() > 0.8 * torch.cuda.max_memory_allocated():\n",
    "        classifier.model.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "    result = classifier(text_preview, topics, multi_label=False)\n",
    "    print(f\"Text: {text_preview[:200]}... -> Topic: {result['labels'][0]}, Scores: {result['scores']}\")\n",
    "    # Move back to GPU if available after processing\n",
    "    if torch.cuda.is_available():\n",
    "        classifier.model.to('cuda')\n",
    "    return result['labels'][0]\n",
    "\n",
    "def extract_ranking(text: str) -> List[Tuple[str, int, float]]:\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []\n",
    "    rankings = {brand: 0.0 for brand in brands}\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\", device_map=\"auto\")\n",
    "\n",
    "    for brand in brands:\n",
    "        sentences = [s for s in text.split('. ') if brand.lower() in s.lower()]\n",
    "        if not sentences:\n",
    "            continue\n",
    "        try:\n",
    "            # Offload if memory is critical\n",
    "            if torch.cuda.memory_allocated() > 0.8 * torch.cuda.max_memory_allocated():\n",
    "                sentiment_pipeline.model.to('cpu')\n",
    "                torch.cuda.empty_cache()\n",
    "            scores = [sentiment_pipeline(s[:512])[0]['score'] for s in sentences]\n",
    "            avg_score = sum(scores) / len(scores) if scores else 0.0\n",
    "            rankings[brand] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sentiment for {brand}: {e}\")\n",
    "            rankings[brand] = 0.0\n",
    "        finally:\n",
    "            if torch.cuda.is_available():\n",
    "                sentiment_pipeline.model.to('cuda')\n",
    "\n",
    "    ranked_brands = sorted(rankings.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [(brand, idx + 1, float(score)) for idx, (brand, score) in enumerate(ranked_brands)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab74f46-3d43-499e-a67f-d9db2fb72f74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ab74f46-3d43-499e-a67f-d9db2fb72f74",
    "outputId": "28132b91-cf60-4502-bfc5-91b2d55fa36c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply topic categorization\n",
    "df['topic'] = df['content'].apply(categorize_topic)\n",
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rsu8Db8wSECW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f1757899021a4a30b6ef49305fbd9603",
      "d9b329c810324784a4a7c4992023cb93",
      "49837abd021745d9b7809059c668206a",
      "47224679777f45caa4a1c7334619646a",
      "6b7c5d5952a74a90ab69201f8787b6c0",
      "de72bd7558fb4ddd990f4866395c2a2e",
      "e2364ba86a0445c589c57da96e92906a",
      "453d8c65ad2f4bc9949cb61c18fe420b",
      "efa92325b16241b798e80cbbd988d7c2",
      "37a19d62230f46759a67a52367821549",
      "a036c5ae3dc54058aac9cddf5463c56f",
      "61da6485b1cd4593979f134a82243e9b",
      "088ac4096c664702a95ee03c1dc3c0bb",
      "92bed983b66e43b89331ae8d91b80b1f",
      "9e669158455e4c02ad590d0adaf3553a",
      "a782caf5d8e545379760236a7537e174",
      "f78b2235be6d474fb58c2716f5a82122",
      "04ef10d56042432f810148d1a555b8b3",
      "78445feb91ed4cd8bb471e529c929944",
      "9944ab2722844fc4ae610c3cb04f9c6e",
      "27689f9e271a4cfb8d860be014124d6f",
      "921fbe40fd2642819fc2e5e6812935fa",
      "818b92b6dd904092a00d949d752c0479",
      "d823db77bad849fbb3f22ee960e9c5b9",
      "079a7991183b417784152041a851988b",
      "1057c52ced904b00a8e0cf24f3abda79",
      "cc2adf33332d47689b8d38aef0d9cc83",
      "069ed6c0bc09439987221cbee8a67eeb",
      "23a4cc535317438da96c7cbf491f9cff",
      "e7af763e724e4deea28f59cfe7797813",
      "83bc6417339c4f93b659a1567c2ef31b",
      "994ade3e51ed469dbdbaa2bb38b59bb5",
      "00c484c101124172b80ba578f8630a70",
      "9d85f0bcc8d548b58cec33b04384aacc",
      "904ce83241f6493cbbbc12bcd20daa12",
      "0e41ebcf527344df8e493eed3e43b7fd",
      "c6856e58a46b4c88a35b700fdfeefa9a",
      "455fd7b546714fa986746ba8d3a98573",
      "9b939ed9063a42bb80e0efbbc2bbbada",
      "661c10df35a343d5ae4a5c530d670d1b",
      "e691c10ad7ff49d596f6114a8f663f2b",
      "0b16415f0a644932a91534f1fef35f90",
      "e2033321737d4aa69836e5e51b8eb7ef",
      "9c5195df46a0407684d4bb7718175acc",
      "852c47fb29454c4e848464ae3db83279",
      "77a4f18663664a8d80d05d3a2c642d5b",
      "0915b42df4b242d1ab3e0e6ca91d5735",
      "b24b662773cd4198abaef0ac27032042",
      "6967e16f060c4d6fb83e203ded9f0e8a",
      "b17fa8ffbdf241cf879afa47167f1142",
      "49c69fce322d4b0aa067032801c0d6d9",
      "bed33f8d052342528fb3c58ca492edd1",
      "2fa6f9ebb2a246d18a810677a0e0cb8b",
      "bd40d0b6d1f946c58de6035c1227ca84",
      "8f4c22f1b789425096c72e0185fd45b5"
     ]
    },
    "executionInfo": {
     "elapsed": 37164,
     "status": "ok",
     "timestamp": 1752016022430,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "Rsu8Db8wSECW",
    "outputId": "07263e6d-a857-48fb-afcb-269ff244b900",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply ranking extraction\n",
    "df['brand_rankings'] = df['content'].apply(extract_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0927e2-1a66-4e62-a2dd-93f9bb65572f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1752016038058,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "1b0927e2-1a66-4e62-a2dd-93f9bb65572f",
    "outputId": "7e66561a-0c8a-42e6-e934-155949700a98",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yDORf7G0TE2-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1752016255955,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "yDORf7G0TE2-",
    "outputId": "1edd4962-416e-4b6b-8179-043a9b21362f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display results\n",
    "df[['url', 'topic', 'brand_rankings']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WZWmpGDiS73u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1752018169969,
     "user": {
      "displayName": "Thao Mi Nguyen",
      "userId": "05122340000116505996"
     },
     "user_tz": -60
    },
    "id": "WZWmpGDiS73u",
    "outputId": "8b7d6774-3056-4ebf-c560-fd2de6ef000d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_rankings(df):\n",
    "    rankings_exploded = df.explode('brand_rankings')\n",
    "    rankings_exploded = rankings_exploded[rankings_exploded['brand_rankings'].notnull()]\n",
    "\n",
    "    rankings_exploded['brand_rankings'] = rankings_exploded['brand_rankings'].apply(\n",
    "        lambda x: {'brand': x[0], 'rank': x[1], 'score': x[2]} if isinstance(x, (list, tuple)) and len(x) == 3 else None\n",
    "    )\n",
    "\n",
    "    rankings_exploded = rankings_exploded[rankings_exploded['brand_rankings'].notnull()]\n",
    "    rankings_df = pd.json_normalize(rankings_exploded['brand_rankings'])\n",
    "    rankings_df.columns = ['brand', 'rank', 'score']\n",
    "\n",
    "    result = pd.concat([rankings_exploded['topic'].reset_index(drop=True), rankings_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Group by topic and brand, compute mean score\n",
    "    temp = result.groupby(['topic', 'brand']).agg({'score': 'mean'}).reset_index()\n",
    "\n",
    "    # Assign ranks based on mean score in descending order (highest score = 1)\n",
    "    temp['rank'] = temp.groupby('topic')['score'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "    # Sort by topic and rank to ensure descending order\n",
    "    temp = temp.sort_values(['topic', 'rank'])\n",
    "\n",
    "    return temp[['topic', 'brand', 'rank', 'score']]\n",
    "\n",
    "df_aggregated = aggregate_rankings(df)\n",
    "print(df_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d665d93-9e1b-46ff-aa01-642cf53b6865",
   "metadata": {
    "id": "7d665d93-9e1b-46ff-aa01-642cf53b6865",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 4. Baseline LLM Brand Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e70f5-30c3-46a7-bb7e-5e3c705aa474",
   "metadata": {
    "id": "072e70f5-30c3-46a7-bb7e-5e3c705aa474",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 5. LLM Brand Ranking with RAG Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477d0f2-fcbd-458b-938c-b6dfc199160e",
   "metadata": {
    "id": "c477d0f2-fcbd-458b-938c-b6dfc199160e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "RefinedWeb columns are explained below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b74cac-9a2c-4da7-b86e-be96825ca350",
   "metadata": {
    "id": "70b74cac-9a2c-4da7-b86e-be96825ca350",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "| Column Name | Description |\n",
    "|-------------|-------------|\n",
    "| `content` | The main textual content of the document record (e.g., the body of a document, article, or code snippet). This will be used as the primary field for training language model and analysis in our study. |\n",
    "| `url` | The URL of the web page or resource from which the content was sourced. |\n",
    "| `timestamp` | The date and time when the web page was crawled or the data was extracted from the source (e.g., Common Crawl). |\n",
    "| `dump` | This refers to the specific Common Crawl (CC) dump from which the data was sourced. CC releases monthly dumps (e.g., CC-MAIN-2023-06), allowing users to trace the data back to its original crawl.|\n",
    "| `segment` | Identifies the segment or subset of the Common Crawl dump from which the record originates.|\n",
    "| `image_urls` | A list of URLs pointing to images found on the web page.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcd526-9a24-47f9-adb0-ca7339659808",
   "metadata": {
    "id": "a3bcd526-9a24-47f9-adb0-ca7339659808",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.1 Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f31c3e-442f-4902-be10-b486fd817bf8",
   "metadata": {
    "id": "30f31c3e-442f-4902-be10-b486fd817bf8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenisation - clean text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r'[\\n\\r]', ' ', text)     # removes newlines and carriage returns\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())     # removes punctuation and lowercase\n",
    "    text = re.sub(r'\\d+', '', text)   # removes digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # whitespace\n",
    "    text = demojize(text)  # convert emojis to text (e.g., 😊 → :smiling_face:)\n",
    "    text = re.sub(r'[^\\w\\s:]', '', text.lower())  # preserve emoji tokens\n",
    "    return text\n",
    "\n",
    "clean_udf = udf(clean_text, StringType())\n",
    "df = df.withColumn(\"clean_text\", clean_udf(col(\"content\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eb2af-c74d-452f-83eb-281953a328d8",
   "metadata": {
    "id": "f61eb2af-c74d-452f-83eb-281953a328d8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.2 Feature Engineering\n",
    "\n",
    "The aim of this part is to extract additional information and columns from the data to enable more detailed sentiment analysis, such as brand mentions and content types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88274bd4-6ec3-4496-9dd6-cf9cae6a6832",
   "metadata": {
    "id": "88274bd4-6ec3-4496-9dd6-cf9cae6a6832",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Extraction of Brand Mentions: *brand_mention* and *mention_count*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16fff8-3f9b-486d-9cea-f10cfa011864",
   "metadata": {
    "id": "9f16fff8-3f9b-486d-9cea-f10cfa011864",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Our analysis is focused on the following **4 brands**: HSBC, LLoyds, Barclays, and Revolut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bfa47-8d4f-4962-9499-67de1aa2a8b2",
   "metadata": {
    "id": "594bfa47-8d4f-4962-9499-67de1aa2a8b2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UK banks\n",
    "BRANDS = [\"barclays\", \"lloyds\", \"hsbc\", \"monzo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d339509-959a-4f4f-9d60-cb93029b110a",
   "metadata": {
    "id": "3d339509-959a-4f4f-9d60-cb93029b110a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Banking-related context terms to confirm brand relevance\n",
    "BANKING_CONTEXT = [\n",
    "    \"finance\", \"financial\", \"bank\", \"banking\", \"account\", \"savings\", \"current\", \"mortgage\", \"loan\", \"credit\", \"debit\", \"card\",\n",
    "    \"app\", \"mobile\", \"online\", \"branch\", \"atm\", \"transfer\", \"fees\", \"overdraft\", \"service\", \"support\"\n",
    "]\n",
    "\n",
    "# Negative context terms to exclude false positives\n",
    "NEGATIVE_CONTEXT = {\n",
    "    \"revolut\": [\"revolution\", \"revolutionary\", \"national revolution\"],\n",
    "    \"barclays\": [\"barclays center\", \"barclays arena\"],\n",
    "    \"lloyds\": [\"lloyds of london\"],\n",
    "    \"hsbc\": [],\n",
    "    \"monzo\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886964a7-a241-48b4-b5fb-e706143abffc",
   "metadata": {
    "id": "886964a7-a241-48b4-b5fb-e706143abffc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def extract_brands_and_counts(text):\n",
    "#     if not isinstance(text, str):\n",
    "#         return [], []\n",
    "#     text_lower = text.lower()\n",
    "#     tokens = word_tokenize(text_lower)\n",
    "\n",
    "#     brands_found = []\n",
    "#     counts = []\n",
    "\n",
    "#     for brand in BRANDS:\n",
    "#         # Initialize count\n",
    "#         brand_count = 0\n",
    "\n",
    "#         # Check for brand in tokens with word boundaries\n",
    "#         brand_pattern = r'\\b' + re.escape(brand) + r'\\b'\n",
    "#         matches = re.findall(brand_pattern, text_lower)\n",
    "#         brand_count += len(matches)\n",
    "\n",
    "#         # Validate with banking context (at least one banking term nearby)\n",
    "#         has_banking_context = False\n",
    "#         for context in BANKING_CONTEXT:\n",
    "#             if context in text_lower:\n",
    "#                 has_banking_context = True\n",
    "#                 break\n",
    "\n",
    "#         # Check for negative context to exclude false positives\n",
    "#         has_negative_context = False\n",
    "#         for negative_term in NEGATIVE_CONTEXT.get(brand, []):\n",
    "#             if negative_term in text_lower:\n",
    "#                 has_negative_context = True\n",
    "#                 break\n",
    "\n",
    "#         # Only include brand if it has banking context and no negative context\n",
    "#         if brand_count > 0 and has_banking_context and not has_negative_context:\n",
    "#             brands_found.append(brand)\n",
    "#             counts.append(brand_count)\n",
    "\n",
    "#     return brands_found, counts\n",
    "\n",
    "# @udf(ArrayType(StringType()))\n",
    "# def extract_brands(text):\n",
    "#     brands, _ = extract_brands_and_counts(text)\n",
    "#     return brands\n",
    "\n",
    "# @udf(ArrayType(IntegerType()))\n",
    "# def extract_mention_counts(text):\n",
    "#     _, counts = extract_brands_and_counts(text)\n",
    "#     return counts\n",
    "\n",
    "# df = df.withColumn(\"brand_name\", extract_brands(col(\"clean_text\")))\n",
    "# df = df.withColumn(\"mention_count\", extract_mention_counts(col(\"clean_text\")))\n",
    "\n",
    "# # Filter rows with at least one valid brand mention\n",
    "# df = df.filter(col(\"brand_name\").isNotNull() & (col(\"brand_name\").getItem(0).isNotNull()))\n",
    "# print(f\"Number of rows with brand mentions: {df.count()}\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216c945-8ad4-435a-98a7-abc5191ba2d9",
   "metadata": {
    "id": "0216c945-8ad4-435a-98a7-abc5191ba2d9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Save Spark Dataframe with brand mentions to Parquet files as a checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658bd36-386f-4099-8e9a-7406bffc28aa",
   "metadata": {
    "id": "7658bd36-386f-4099-8e9a-7406bffc28aa",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.write.mode(\"overwrite\").parquet(\"data/temp/olmo_brand_mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973a4d3-7c0f-4716-90ae-0bdabea777f2",
   "metadata": {
    "id": "4973a4d3-7c0f-4716-90ae-0bdabea777f2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brand_mentions_dir = \"data/temp/olmo_brand_mentions\"\n",
    "df = spark.read.parquet(f\"{brand_mentions_dir}/*.parquet\")\n",
    "print(f\"Number of rows with brand mentions: {df.count()}\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed86e6-3d4e-4d22-9dea-54f156e1f56f",
   "metadata": {
    "id": "4bed86e6-3d4e-4d22-9dea-54f156e1f56f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Brand Mentions by Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b32b37-034c-4d60-a214-90afa7cc9aa7",
   "metadata": {
    "id": "d8b32b37-034c-4d60-a214-90afa7cc9aa7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Viewing mentions for each brand\n",
    "for brand in BRANDS:\n",
    "    print(f\"\\n=== Documents mentioning '{brand}' ===\")\n",
    "    brand_df = df.filter(array_contains(col(\"brand_name\"), brand))\n",
    "    brand_df.select(\"clean_text\", \"brand_name\", \"mention_count\").show()\n",
    "    print(f\"Total number of documents in RefinedWeb dataset mentioning '{brand}': {brand_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc79bb-4756-4944-a900-488ed54c2e3f",
   "metadata": {
    "id": "b8fc79bb-4756-4944-a900-488ed54c2e3f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Classification of Brand-related Content: *content_type*\n",
    "\n",
    "Content types help tailor sentiment methods, i.e. VADER for user-generated, FinBERT for news)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da944af8-ed57-496b-add8-1116f299352b",
   "metadata": {
    "id": "da944af8-ed57-496b-add8-1116f299352b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_content(url, clean_text):\n",
    "    if not isinstance(url, str):\n",
    "        url = \"\"\n",
    "    if not isinstance(clean_text, str):\n",
    "        clean_text = \"\"\n",
    "\n",
    "    url = url.lower()\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    # Social media or blogs\n",
    "    user_gen_domains = [\"reddit\", \"twitter\", \"x.com\", \"facebook\", \"linkedin\", \"instagram\", \"tiktok\", \"pinterest\", \"forum\", \"discuss\", \"community\", \"medium\", \"wordpress\", \"blogger\", \"tumblr\", \"substack\", \"blog\"]\n",
    "    if any(domain in url for domain in user_gen_domains):\n",
    "        return \"user_generated\"\n",
    "\n",
    "    # News article: Reputable news sources or news-related keywords\n",
    "    news_domains = [\"bbc\", \"guardian\", \"telegraph\", \"ft.com\", \"reuters\", \"bloomberg\", \"cnn\", \"nytimes\", \"independent\", \"dailymail\", \"sky.com\", \"news\", \"times\"]\n",
    "    news_keywords = [\"breaking news\"]\n",
    "    if any(domain in url for domain in news_domains) or any(keyword in clean_text for keyword in news_keywords):\n",
    "        return \"news_article\"\n",
    "\n",
    "    # Customer review: Review platforms or review-related keywords\n",
    "    review_keywords = [\"trustpilot\", \"feefo\", \"reviews\", \"yelp\", \"google.com/reviews\"]\n",
    "    if any(domain in url for domain in review_keywords) or any(keyword in clean_text for keyword in review_keywords):\n",
    "        return \"customer_review\"\n",
    "\n",
    "    # Regulatory document: Official or compliance-related sources or keywords\n",
    "    regulatory_keywords = [\"fca.org.uk\", \"bankofengland\", \"gov.uk\"]\n",
    "    if any(domain in url for domain in regulatory_keywords) or any(keyword in clean_text for keyword in regulatory_keywords):\n",
    "        return \"regulatory_document\"\n",
    "\n",
    "    # Advertising content: Promotional keywords\n",
    "    advertising_keywords = [\"ads\", \"campaign\", \"promo\", \"sponsor\", \"advert\", \"promotion\", \"ad\"]\n",
    "    if any(term in url for term in advertising_keywords):\n",
    "        return \"advertising_content\"\n",
    "\n",
    "    # Owned media: Brand or institutional domains or brand mentions\n",
    "    owned_media_domains = [\"gov.uk\", \"ac.uk\", \"co.uk\", \"barclays\", \"lloyds\", \"hsbc\", \"monzo\"]\n",
    "    if any(domain in url for domain in owned_media_domains):\n",
    "        return \"owned_media\"\n",
    "\n",
    "    # Forum post: Specific forum platforms or discussion keywords\n",
    "    forum_keywords = [\"moneysavingexpert\", \"thestudentroom\", \"forums\"]\n",
    "    if any(domain in url for domain in forum_keywords) or any(keyword in clean_text for keyword in forum_keywords):\n",
    "        return \"forum_post\"\n",
    "\n",
    "    # FAQ/Knowledge base: Support or informational keywords\n",
    "    faq_keywords = [\"faq\", \"how to\", \"guide\", \"tutorial\"]\n",
    "    if any(keyword in url for keyword in faq_keywords) or any(keyword in clean_text for keyword in faq_keywords):\n",
    "        return \"faq_knowledge_base\"\n",
    "\n",
    "    # Default: Other\n",
    "    return \"miscellaneous\"\n",
    "\n",
    "content_type_udf = udf(classify_content, StringType())\n",
    "df = df.withColumn(\"content_type\", content_type_udf(col(\"url\"), col(\"clean_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80381bd0-c90e-4d04-a561-f606a6f94e40",
   "metadata": {
    "id": "80381bd0-c90e-4d04-a561-f606a6f94e40",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab61e44-9a38-4c42-9578-61148f0f1cdf",
   "metadata": {
    "id": "7ab61e44-9a38-4c42-9578-61148f0f1cdf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Summary of Final Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2201b9-0c3c-48de-8534-299eac595447",
   "metadata": {
    "id": "0e2201b9-0c3c-48de-8534-299eac595447",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "| Column Name    | Description                                                                 |\n",
    "|----------------|-----------------------------------------------------------------------------|\n",
    "| `text`         | The original textual content of the document record (e.g., the body of an article or code snippet), retained as the primary source text for analysis. |\n",
    "| `clean_text`   | The processed version of the `text` column, where newlines, punctuation, digits, and excessive whitespace are removed, text is lowercased, and emojis are converted to text for consistency in analysis. |\n",
    "| `url`          | The URL of the web page or resource from which the content was sourced, used for content type classification and brand context. |\n",
    "| `brand_name`   | An array of organization names extracted from `clean_text`, representing brand mentions for targeted sentiment analysis. |\n",
    "| `mention_count`| The number of brand mentions (size of the `brand_name` array) in each row, quantifying the frequency of brand references. |\n",
    "| `content_type` | A categorized label (e.g., `user_generated`, `news_article`, `customer_review`, etc.) assigned based on the `url`, indicating the type of content for further analysis. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac84abe-c6e2-4bdb-bfbd-08dbc313ccd2",
   "metadata": {
    "id": "9ac84abe-c6e2-4bdb-bfbd-08dbc313ccd2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10282244-9c6a-429c-b667-0283e329b34c",
   "metadata": {
    "id": "10282244-9c6a-429c-b667-0283e329b34c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2073e99-1894-41c8-8049-df3d9423f525",
   "metadata": {
    "id": "c2073e99-1894-41c8-8049-df3d9423f525",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361545ab-175d-4f82-83f4-6b96a4e415ea",
   "metadata": {
    "id": "361545ab-175d-4f82-83f4-6b96a4e415ea",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 4. Brand Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc797f4e-2979-456e-a957-9ece9bead94d",
   "metadata": {
    "id": "dc797f4e-2979-456e-a957-9ece9bead94d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "In this section, sentiment analysis is performed on UK bank brand mentions using a hybrid approach combining lexicon-based (VADER) and a transformer-based model (FinBERT). The aim is to analyze the emotional tone (positive, neutral, negative) of the brand mentions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a25b6a-5335-4d1d-ae83-d5068a02d650",
   "metadata": {
    "id": "75a25b6a-5335-4d1d-ae83-d5068a02d650",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Lexicon-Based (VADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9acaf3-f714-4086-b039-fc56dcc4c7e5",
   "metadata": {
    "id": "0c9acaf3-f714-4086-b039-fc56dcc4c7e5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The following code performs brand sentiment analysis using NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner), a lexicon-based tool specifically designed for detecting sentiment in user-generated texts. VADER is fast and handles slang, emojis, and short texts well, making it ideal for analysing sentiment in data sources such as social media and reviews.\n",
    "\n",
    "VADER calculates 4 sentiment metrics for each text input:\n",
    "- `vader_score` (compound score): A normalized weighted composite score ranging from -1 (negative) to +1 (positive). Derived from the sum of valence scores of individual words, adjusted for modifiers (e.g., \"very good\" amplifies positivity).\n",
    "- `positive_score`, `neutral_score`, `negative_score`: Proportional metrics representing the text's positive, neutral, and negative sentiment (each ranges 0–1). The 3 scores sum to 1.\n",
    "\n",
    "`sentiment_label` is assigned based on the compound `vader_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c366d1b-060d-48ee-930a-5b6252155830",
   "metadata": {
    "id": "7c366d1b-060d-48ee-930a-5b6252155830",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise VADER\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculates VADER sentiment\n",
    "def vader_sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"compound\": 0.0, \"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0}\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores\n",
    "\n",
    "# Schema for VADER output\n",
    "vader_schema = StructType([\n",
    "    StructField(\"compound\", FloatType(), nullable=True),\n",
    "    StructField(\"pos\", FloatType(), nullable=True),\n",
    "    StructField(\"neu\", FloatType(), nullable=True),\n",
    "    StructField(\"neg\", FloatType(), nullable=True)\n",
    "])\n",
    "\n",
    "vader_udf = udf(vader_sentiment, vader_schema)\n",
    "df = df.withColumn(\"vader_sentiment\", vader_udf(col(\"clean_text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237b654-ade7-4a37-ab0f-09b00d4479a2",
   "metadata": {
    "id": "a237b654-ade7-4a37-ab0f-09b00d4479a2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Sentiment Scores and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a309eb-4e50-4b1f-ac4d-3d7b0d79fbea",
   "metadata": {
    "id": "21a309eb-4e50-4b1f-ac4d-3d7b0d79fbea",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"vader_score\", col(\"vader_sentiment.compound\"))\n",
    "df = df.withColumn(\"positive_score\", col(\"vader_sentiment.pos\"))\n",
    "df = df.withColumn(\"neutral_score\", col(\"vader_sentiment.neu\"))\n",
    "df = df.withColumn(\"negative_score\", col(\"vader_sentiment.neg\"))\n",
    "\n",
    "# Sentiment Label\n",
    "df = df.withColumn(\"sentiment_label\",\n",
    "    when(col(\"vader_score\") > 0.05, \"Positive\")\n",
    "    .when(col(\"vader_score\") < -0.05, \"Negative\")\n",
    "    .otherwise(\"Neutral\"))\n",
    "\n",
    "df = df.drop(\"vader_sentiment\")\n",
    "\n",
    "print(\"\\nVADER Sentiment Scores and Labels:\")\n",
    "df.select(\n",
    "    \"clean_text\", \"brand_name\", \"mention_count\", \"content_type\", \"vader_score\", \"positive_score\",\n",
    "    \"neutral_score\", \"negative_score\", \"sentiment_label\"\n",
    ").show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781b483-c271-4753-8c2d-574a482ed527",
   "metadata": {
    "id": "3781b483-c271-4753-8c2d-574a482ed527",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Overall Sentiment Aggregation: *avg_vader_score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed40fcb-a38a-4370-80cd-438bb42e7753",
   "metadata": {
    "id": "aed40fcb-a38a-4370-80cd-438bb42e7753",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Associates sentiment with each brand\n",
    "df_exploded = df.select(\n",
    "    explode(col(\"brand_name\")).alias(\"brand\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"content_type\")\n",
    ")\n",
    "\n",
    "# Sentiment by brand and content_type\n",
    "sentiment_summary = df_exploded.groupBy(\"brand\", \"content_type\").agg(\n",
    "    avg(\"vader_score\").alias(\"avg_vader_score\")\n",
    ").orderBy(\"brand\", \"content_type\")\n",
    "\n",
    "# Sentiment label\n",
    "sentiment_summary = sentiment_summary.withColumn(\n",
    "    \"avg_sentiment_label\",\n",
    "    when(col(\"avg_vader_score\") > 0.05, \"Positive\")\n",
    "    .when(col(\"avg_vader_score\") < -0.05, \"Negative\")\n",
    "    .otherwise(\"Neutral\")\n",
    ")\n",
    "\n",
    "print(\"VADER Sentiment Summary by Brand and Content Type:\")\n",
    "sentiment_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f54a9-a9d0-4f70-9ce3-48909f170f43",
   "metadata": {
    "id": "476f54a9-a9d0-4f70-9ce3-48909f170f43",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.2 Transformer-Based (FinBERT)\n",
    "**FinBERT** model is implemented for brand sentiment analysis of UK financial services brands due to its:\n",
    "- **Domain-specialisation**:  Explicitly trained on financial texts (10M+ finance docs), including financial news, analyst reports, earnings call transcripts, SEC/FCA filings, and other regulatory documents. It has good understanding of key financial concepts, such as, financial metrics, market movements, and regulatory language.\n",
    "- **Sentiment granularity**: 3-class (positive/neutral/negative)\n",
    "- **Numerical sensitivity**: Handles earnings and percentages well.\n",
    "\n",
    "FinBERT understands context better than VADER, excelling in more complex texts such as news articles, regulatory documents, and reports.\n",
    "\n",
    "The following outputs are computed:\n",
    "- `finbert_label` – the sentiment class with the highest average probability across all chunks\n",
    "- `finbert_score` – the sentiment polarity score, calculated as Positive - Negative probability.\n",
    "- `finbert_confidence`: How confident FinBERT is about its prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81924c-5576-4da3-b8f2-676fa40d724d",
   "metadata": {
    "id": "fc81924c-5576-4da3-b8f2-676fa40d724d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# CPU / GPU checks\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cpu\":\n",
    "    print(\"Warning: Flash Attention requires a CUDA-capable GPU. Falling back to standard attention.\")\n",
    "else:\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "# Enables Flash Attention\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "\n",
    "# FinBERT tokenizer and model\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\", use_fast=True)\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\n",
    "\n",
    "# Additional optimisation using xformers\n",
    "try:\n",
    "    from xformers.ops import memory_efficient_attention\n",
    "    print(\"Using xformers for memory-efficient attention\")\n",
    "except ImportError:\n",
    "    print(\"xformers not installed. Using PyTorch Flash Attention.\")\n",
    "\n",
    "# FinBERT pipeline\n",
    "finbert_pipeline = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=finbert_model,\n",
    "    tokenizer=finbert_tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    torch_dtype=torch.float16,  # Keep for memory efficiency\n",
    "    return_all_scores=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1cdaa-95cc-42e7-b7ae-f84c445722af",
   "metadata": {
    "id": "5cd1cdaa-95cc-42e7-b7ae-f84c445722af",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The large document texts are then split into context-level chunks. That is, each chunk contains a brand mentions and captures ±2 sentences surrounding each mention.\n",
    "\n",
    "The text is first split into individual sentences, with sentences containing brand mentions being flagged. Chunks are consequently formed around each brand mention with ±2 sentences being appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b6cce-cc01-43ef-837f-3303bfd5adc7",
   "metadata": {
    "id": "f00b6cce-cc01-43ef-837f-3303bfd5adc7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits text into context-based chunks\n",
    "def prepare_chunks(text, tokenizer, brands=None, max_tokens=510):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "\n",
    "    # If no brands provided, return empty list to avoid processing\n",
    "    if not brands:\n",
    "        return []\n",
    "\n",
    "    # Split text into sentences using NLTK\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    if not sentences:\n",
    "        return []\n",
    "\n",
    "    # Normalize brands for case-insensitive matching\n",
    "    brands = [brand.lower() for brand in brands]\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    # Identify sentences containing brand mentions\n",
    "    brand_mention_indices = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "        # Check if any brand is mentioned in the sentence (case-insensitive)\n",
    "        if any(brand in sentence.lower() for brand in brands):\n",
    "            brand_mention_indices.append(i)\n",
    "\n",
    "    if not brand_mention_indices:\n",
    "        return []\n",
    "\n",
    "    # Create chunks around each brand mention\n",
    "    for idx in brand_mention_indices:\n",
    "        # Define context window: ±2 sentences (up to 5 sentences total)\n",
    "        start_idx = max(0, idx - 2)\n",
    "        end_idx = min(len(sentences), idx + 3)  # idx + 2 + 1 to include the mention sentence\n",
    "        context_sentences = sentences[start_idx:end_idx]\n",
    "\n",
    "        # Initialize chunk and token count\n",
    "        current_chunk = []\n",
    "        current_token_count = 0\n",
    "\n",
    "        for sentence in context_sentences:\n",
    "            if not sentence.strip():\n",
    "                continue\n",
    "\n",
    "            # Tokenize sentence to count tokens\n",
    "            tokens = tokenizer.tokenize(sentence)\n",
    "            token_count = len(tokens)\n",
    "\n",
    "            # If a single sentence exceeds max_tokens, truncate it\n",
    "            if token_count > max_tokens:\n",
    "                truncated_tokens = tokens[:max_tokens]\n",
    "                truncated_sentence = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "                chunks.append(truncated_sentence)\n",
    "                continue\n",
    "\n",
    "            # If adding sentence exceeds max_tokens, finalize current chunk\n",
    "            if current_token_count + token_count > max_tokens:\n",
    "                if current_chunk:\n",
    "                    chunk_text = \" \".join(current_chunk)\n",
    "                    if chunk_text.strip():\n",
    "                        chunks.append(chunk_text)\n",
    "                current_chunk = [sentence]\n",
    "                current_token_count = token_count\n",
    "            else:\n",
    "                # Add sentence to current chunk\n",
    "                current_chunk.append(sentence)\n",
    "                current_token_count += token_count\n",
    "\n",
    "        # Append any remaining chunk\n",
    "        if current_chunk:\n",
    "            chunk_text = \" \".join(current_chunk)\n",
    "            if chunk_text.strip():\n",
    "                chunks.append(chunk_text)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0deaf6-c496-44b2-93d0-e43e97fd9f6a",
   "metadata": {
    "id": "4c0deaf6-c496-44b2-93d0-e43e97fd9f6a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyzes sentiment of text using FinBERT, processing chunks around brand mentions\n",
    "def analyze_finbert(text):\n",
    "    global BRANDS\n",
    "    try:\n",
    "        chunks = prepare_chunks(text, finbert_tokenizer, brands=BRANDS)\n",
    "        if not chunks or all(not c.strip() for c in chunks):\n",
    "            return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "\n",
    "        results = finbert_pipeline(chunks)\n",
    "        cumulative_scores = {\"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0}\n",
    "        confidences = []\n",
    "        count = 0\n",
    "\n",
    "        for r in results:\n",
    "            if isinstance(r, list):\n",
    "                for entry in r:\n",
    "                    label = entry[\"label\"].lower()\n",
    "                    score = entry[\"score\"]\n",
    "                    cumulative_scores[label] += score\n",
    "                confidences.append(max(entry[\"score\"] for entry in r))\n",
    "                count += 1\n",
    "\n",
    "        if count == 0:\n",
    "            return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "\n",
    "        # Normalizes all the scores\n",
    "        avg_scores = {k: v / count for k, v in cumulative_scores.items()}\n",
    "        avg_confidence = sum(confidences) / count\n",
    "\n",
    "        # Polarity score\n",
    "        polarity = avg_scores[\"positive\"] - avg_scores[\"negative\"]\n",
    "\n",
    "        # Final predicted label\n",
    "        if abs(polarity) < 0.15:\n",
    "            final_label = \"neutral\"\n",
    "        else:\n",
    "            final_label = \"positive\" if polarity > 0 else \"negative\"\n",
    "\n",
    "        return (\n",
    "            final_label,\n",
    "            round(polarity, 4),\n",
    "            round(avg_confidence, 4),\n",
    "            {k: round(v, 4) for k, v in avg_scores.items()}\n",
    "        )\n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        torch.cuda.empty_cache()\n",
    "        return analyze_finbert_vader_style(text)\n",
    "    except Exception as e:\n",
    "        print(f\"FinBERT error on text {text[:50]}...: {str(e)}\")\n",
    "        return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dfe27-a1a2-42b5-8049-78561aab2a21",
   "metadata": {
    "id": "db7dfe27-a1a2-42b5-8049-78561aab2a21",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Row index for joining\n",
    "df = df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# Convert to Pandas for transformer processing\n",
    "pandas_df = df.select(\"row_id\", \"text\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0994-d7cc-448d-8983-803e16458234",
   "metadata": {
    "id": "157d0994-d7cc-448d-8983-803e16458234",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Runs analysis\n",
    "finbert_results = [analyze_finbert(text) for text in pandas_df[\"text\"]]\n",
    "\n",
    "# Sentiment label, score and confidence\n",
    "pandas_df[\"finbert_label\"] = [r[0] for r in finbert_results]\n",
    "pandas_df[\"finbert_score\"] = [r[1] for r in finbert_results]\n",
    "pandas_df[\"finbert_confidence\"] = [r[2] for r in finbert_results]\n",
    "\n",
    "# Individual sentiment scores\n",
    "pandas_df[\"finbert_dist_positive\"] = [r[3][\"positive\"] for r in finbert_results]\n",
    "pandas_df[\"finbert_dist_neutral\"] = [r[3][\"neutral\"] for r in finbert_results]\n",
    "pandas_df[\"finbert_dist_negative\"] = [r[3][\"negative\"] for r in finbert_results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03afd9b-6a24-42d2-af00-080bb2422fd9",
   "metadata": {
    "id": "e03afd9b-6a24-42d2-af00-080bb2422fd9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV\n",
    "finbert_csv = \"data/finbert_results.csv\"\n",
    "pandas_df[[\n",
    "    \"row_id\", \"finbert_label\", \"finbert_score\", \"finbert_confidence\",\n",
    "    \"finbert_dist_positive\", \"finbert_dist_neutral\", \"finbert_dist_negative\"\n",
    "]].to_csv(finbert_csv, index=False)\n",
    "\n",
    "# Transforms back to Spark\n",
    "transformer_df = spark.read.csv(finbert_csv, header=True, inferSchema=True)\n",
    "df = df.join(transformer_df, \"row_id\").drop(\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84892ce1-9856-4015-bf24-476bacde2236",
   "metadata": {
    "id": "84892ce1-9856-4015-bf24-476bacde2236",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nFinBERT Sentiment Scores:\")\n",
    "df.select(\n",
    "     \"clean_text\", \"brand_name\", \"mention_count\", \"content_type\",\n",
    "    \"finbert_label\", \"finbert_score\", \"finbert_confidence\", \"finbert_dist_positive\", \"finbert_dist_neutral\", \"finbert_dist_negative\"\n",
    ").show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c259c5-bf9d-4c2f-b5c5-04698d61057e",
   "metadata": {
    "id": "b4c259c5-bf9d-4c2f-b5c5-04698d61057e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.3 Hybrid Approach (Combining VADER and FinBERT labels)\n",
    "The following section combines VADER and FinBERT predictions, weighted by `content_type`. VADER is up-weighted for `user_generated` and `customer_review`, and FinBERT for `news_article` and `regulatory_document`. This outputs `hybrid_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dceb2fc-0d71-4b83-959d-a6fd581e7ec8",
   "metadata": {
    "id": "6dceb2fc-0d71-4b83-959d-a6fd581e7ec8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def hybrid_sentiment(vader_score, finbert_score, content_type):\n",
    "    if vader_score is None or finbert_score is None:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if content_type == \"user_generated\":\n",
    "        combined_score = (vader_score * 0.6) + (finbert_score * 0.4) # adjust weight if necessary\n",
    "    # Use only VADER when finbert_score is 0\n",
    "    else:\n",
    "        # Use only FinBERT for all other content types\n",
    "        combined_score = finbert_score\n",
    "\n",
    "    # Sentiment thresholds\n",
    "    if combined_score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif combined_score < -0.05:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "df = df.withColumn(\"hybrid_sentiment_label\", hybrid_sentiment(\n",
    "    col(\"vader_score\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"content_type\")\n",
    "))\n",
    "\n",
    "print(\"\\nHybrid Sentiment Labels based on VADER and FinBERT results:\")\n",
    "df.select(\n",
    "    \"clean_text\", \"brand_name\", \"mention_count\", \"content_type\", \"hybrid_sentiment_label\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea05365-b1ef-4efc-b0be-4574d64dcb3a",
   "metadata": {
    "id": "dea05365-b1ef-4efc-b0be-4574d64dcb3a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 5. Brand-Specific Analysis\n",
    "\n",
    "The objective of this section is to delve into sentiment insights for specific brands (e.g Lloyds, Barclays), exploring how sentiment varies by content type, with visualizations for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac738a5b-99f0-4ba9-a410-2f8c79bd0d98",
   "metadata": {
    "id": "ac738a5b-99f0-4ba9-a410-2f8c79bd0d98",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brand_sentiment_df = df.select(\n",
    "    explode(arrays_zip(col(\"brand_name\"), col(\"mention_count\"))).alias(\"exploded\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"sentiment_label\"),\n",
    "    col(\"finbert_label\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"finbert_confidence\"),\n",
    "    col(\"hybrid_sentiment_label\")\n",
    ").select(\n",
    "    col(\"exploded.brand_name\").alias(\"brand\"),\n",
    "    col(\"exploded.mention_count\").alias(\"mentions\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"sentiment_label\"),\n",
    "    col(\"finbert_label\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"finbert_confidence\"),\n",
    "    col(\"hybrid_sentiment_label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404ad95-8978-4e85-a74a-bfa872b8a406",
   "metadata": {
    "id": "f404ad95-8978-4e85-a74a-bfa872b8a406",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Sentiment by Brand and Content Type\n",
    "\n",
    "This reveals which content types drive positive or negative sentiment which can guide brand reputation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d92d31-765b-4bd8-b847-e1d26edae48e",
   "metadata": {
    "id": "34d92d31-765b-4bd8-b847-e1d26edae48e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brand_specific_df = brand_sentiment_df.filter(col(\"brand\").isin(BRANDS))\n",
    "\n",
    "# Sentiment summaries for each brand\n",
    "for brand in BRANDS:\n",
    "    brand_df = brand_specific_df.filter(col(\"brand\") == brand)\n",
    "\n",
    "    brand_summary = brand_df.groupBy(\n",
    "        \"brand\", \"content_type\", \"hybrid_sentiment_label\"\n",
    "    ).agg({\"mentions\": \"sum\"}).withColumnRenamed(\"sum(mentions)\", \"total_mentions\")\n",
    "\n",
    "    print(f\"\\nBrand Sentiment Summary for {brand.capitalize()}:\")\n",
    "    brand_summary.orderBy(\"content_type\", \"hybrid_sentiment_label\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a34a1c-e8e2-4c2f-8d58-56e991c590f0",
   "metadata": {
    "id": "88a34a1c-e8e2-4c2f-8d58-56e991c590f0",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 6. Filtering Positive and Negative Brand Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48856a-5153-4ae0-a3a3-728477171b37",
   "metadata": {
    "id": "3d48856a-5153-4ae0-a3a3-728477171b37",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "From here onwards, the analysis will be done on a brand-level. The analysis will be done on 1 brand at a time, with HSBC being the first one. Thus, HSBC mentions are filtered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71a0e0-c7da-4151-89d4-54849eca3e0e",
   "metadata": {
    "id": "ef71a0e0-c7da-4151-89d4-54849eca3e0e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hsbc_df = df.filter(array_contains(col(\"brand_name\"), \"hsbc\"))\n",
    "# hsbc_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a65d59-359b-429a-a26c-ec647ab5a77a",
   "metadata": {
    "id": "63a65d59-359b-429a-a26c-ec647ab5a77a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Extracting only positive and only negative brand mentions for HSBC and saving them to 2 Parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41066dd2-847c-41b3-8f28-810660522984",
   "metadata": {
    "id": "41066dd2-847c-41b3-8f28-810660522984",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive_hsbc_df.write.mode(\"overwrite\").parquet(\"data/filtered_brand_mentions/hsbc_positive_mentions\")\n",
    "# negative_hsbc_df.write.mode(\"overwrite\").parquet(\"data/filtered_brand_mentions/hsbc_negative_mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0027d4-3e97-4f88-9a8b-e5d04fc7b554",
   "metadata": {
    "id": "0c0027d4-3e97-4f88-9a8b-e5d04fc7b554",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 7. RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bd6c1-6853-4244-9d74-30f47248dc10",
   "metadata": {
    "id": "0f4bd6c1-6853-4244-9d74-30f47248dc10",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from pydantic import Field\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53c90f-dc85-4696-8217-efa3a4cc7791",
   "metadata": {
    "id": "1e53c90f-dc85-4696-8217-efa3a4cc7791",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lgging for tracking pipeline progress and errors\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7a2be-0675-42ec-9594-a62f9c7a5718",
   "metadata": {
    "id": "b3e7a2be-0675-42ec-9594-a62f9c7a5718",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install llama-cpp-python --timeout 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d741a-14df-4dc0-acfb-128469636d85",
   "metadata": {
    "id": "1c0d741a-14df-4dc0-acfb-128469636d85",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Using RAG, the filtered data will be fed into the **OLMo 2 model**. The OLMo 2 Model class was defined using Hugging Face implementation.\n",
    "\n",
    "OLMo 2 model was initialised with **quantization**. Quantization lowers the memory requirements of loading and using a model by storing the weights in a lower precision while trying to preserve as much accuracy as possible. Weights are traditionally stored in full-precision (fp32) floating point representations, but half-precision (fp16 or bf16) have become increasingly popular data types given the large size of models. The chosen OLMo-2-0425-1B-Instruct-GGUF model is already quantized and is suitable for local deployment.\n",
    "\n",
    "The init function initializes the OLMo 2 model. The generate function includes the following arguments:\n",
    "* prompt: Input prompt or question\n",
    "* context: Optional list of context strings to include (this is where we inject sentiment)\n",
    "* max_new_tokens: Maximum number of new tokens to generate\n",
    "* do_sample: Whether to use sampling for generation\n",
    "* top_k: Number of highest probability tokens to consider\n",
    "* top_p: Cumulative probability cutoff for top-p sampling\n",
    "\n",
    "This outputs a string of generated text responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13781323-06b4-40f6-9a24-87c17c9a9c2e",
   "metadata": {
    "id": "13781323-06b4-40f6-9a24-87c17c9a9c2e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from llama_cpp import Llama  # for GGUF support\n",
    "\n",
    "class OLMo2Model:\n",
    "    def __init__(self, model_path: str = \"allenai/OLMo-2-0425-1B-Instruct-GGUF\"):\n",
    "\n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-2-0425-1B-Instruct\")\n",
    "\n",
    "        # Load the pre-quantized GGUF model using llama-cpp-python\n",
    "        self.model = Llama(\n",
    "            model_path=model_path,\n",
    "            n_gpu_layers=0,  # set to a positive number if using GPU\n",
    "            n_ctx=2048,      # context length - adjust based on model capabilities\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Device handling is managed by llama-cpp-python\n",
    "        self.device = \"cpu\"  # GGUF model defaults to CPU; GPU support depends on llama-cpp-python build\n",
    "\n",
    "    def generate(self, prompt: str, context: list = None, max_new_tokens: int = 100, temperature: float = 0.7, top_k: int = 50, top_p: float = 0.95) -> str:\n",
    "\n",
    "        # Combine context with prompt if provided\n",
    "        if context:\n",
    "            context_text = \" \".join(context)\n",
    "            full_prompt = f\"Context: {context_text}\\nQuestion: {prompt}\"\n",
    "        else:\n",
    "            full_prompt = prompt\n",
    "\n",
    "        # Generate response using the GGUF model\n",
    "        output = self.model(\n",
    "            full_prompt,\n",
    "            max_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            stop=[\"<|endoftext|>\"]  # Stop token based on OLMo 2 chat template\n",
    "        )\n",
    "        return output[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Initializing model\n",
    "olmo2 = OLMo2Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9f09e-a896-40c1-85af-3ab2e5ed9b8e",
   "metadata": {
    "id": "fcc9f09e-a896-40c1-85af-3ab2e5ed9b8e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.1 Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f0863-4d0a-490c-bb6b-cb2e4739107f",
   "metadata": {
    "id": "102f0863-4d0a-490c-bb6b-cb2e4739107f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "A vector store is a database that stores text embeddings (numerical representations of text generated by a model like BERT). These embeddings enable efficient similarity searches to retrieve relevant documents based on semantic meaning rather than exact keyword matches.\n",
    "\n",
    "The FAISS index is implemented here. First, the cleaned text is converted into a vector using Sentence Transformer (all-MiniLM-L6-v2). Secondly, we build the FAISS index for fast search by taking all of the dataset vectors. It will then find the most similar items to a new query via FAISS. Lastly, FAISS returns similar vectors and documents.\n",
    "\n",
    "This function processes data, creates vector embeddings from the cleaned text, and creates a vector store. This includes the following arguments:\n",
    "\n",
    "* df: Spark DataFrame containing text data (e.g., hsbc_df)\n",
    "* sentiment_filter: Optional filter for sentiment (e.g., \"Positive\" or \"Negative\")\n",
    "* index_path: File path to save the FAISS index\n",
    "* metadata_path: File path to save the metadata CSV\n",
    "\n",
    "It returns returns a tuple: (FAISS index, list of text data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c5f18-c7f1-40f6-9d62-39ae1ddacb82",
   "metadata": {
    "id": "bf1c5f18-c7f1-40f6-9d62-39ae1ddacb82",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def create_vector_store(df, sentiment_filter=None, index_path=\"data/vector_store/hsbc_index.faiss\", metadata_path=\"data/vector_store/metadata.csv\"):\n",
    "\n",
    "    # Filter dataframe based on sentiment if specified\n",
    "    if sentiment_filter:\n",
    "        df_filtered = df.filter(col(\"hybrid_sentiment_label\") == sentiment_filter)\n",
    "    else:\n",
    "        df_filtered = df\n",
    "\n",
    "    # Extracts cleaned text and converts to vector embeddings\n",
    "    texts = [row[\"clean_text\"] for row in df_filtered.select(\"clean_text\").collect()]\n",
    "    embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Create directories and save the index and metadata\n",
    "    os.makedirs(\"data/vector_store\", exist_ok=True)\n",
    "    faiss.write_index(index, index_path)\n",
    "    metadata = pd.DataFrame({\"text\": texts, \"sentiment\": [sentiment_filter] * len(texts) if sentiment_filter else [\"Mixed\"] * len(texts)})\n",
    "    metadata.to_csv(metadata_path, index=False)\n",
    "    logging.info(f\"Saved vector store to {index_path} and metadata to {metadata_path}\")\n",
    "    return index, texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7914e-c014-491f-8258-89674eff4e2c",
   "metadata": {
    "id": "13c7914e-c014-491f-8258-89674eff4e2c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.2 RAG Service and Query System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d061f2-e2b6-455d-8eaa-ace1a55e8a7d",
   "metadata": {
    "id": "75d061f2-e2b6-455d-8eaa-ace1a55e8a7d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "RAG combines a **retrieval** step (retrieves relevant documents from the vector store) with a **generation** step (using OLMo 2 to generate answers). This enhances the model's responses by grounding them in specific and retrieved context.\n",
    "\n",
    "A custom **retriever** for brand sentiment data is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506dacc-0e21-4924-805c-389bd516005e",
   "metadata": {
    "id": "f506dacc-0e21-4924-805c-389bd516005e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BrandSentimentRetriever(BaseRetriever):\n",
    "    index: any = Field(..., description=\"FAISS index for vector search\")\n",
    "    metadata_df: pd.DataFrame = Field(..., description=\"DataFrame containing metadata\")\n",
    "    embedding_model: any = Field(..., description=\"SentenceTransformer model\")\n",
    "    top_k: int = Field(default=5, description=\"Number of documents to retrieve\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True # allowing non-serializable and non-standard types (like a FAISS index object)\n",
    "\n",
    "    # Retrieves relevant documents based on query embedding similarity\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager=None) -> list[Document]: # query - User input string to search for; run_manager - optional LangChain run manager\n",
    "\n",
    "        # Encodes query\n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "\n",
    "        # Searches the index\n",
    "        distances, indices = self.index.search(query_embedding, self.top_k)\n",
    "\n",
    "        # Returns documents with metadata\n",
    "        documents = []\n",
    "        for idx in indices[0]:\n",
    "            row = self.metadata_df.iloc[idx]\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=row['text'],\n",
    "                    metadata={\n",
    "                        'sentiment': row.get('sentiment', 'N/A'),\n",
    "                        'brand': 'HSBC'\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        return documents # retrieved list of documents with content and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1f5ce-3428-4565-9812-ae2560c3835d",
   "metadata": {
    "id": "37f1f5ce-3428-4565-9812-ae2560c3835d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "OLMo 2 model is integrated with the retriever to generate text responses. The **generator** is defined here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0f9ad-d4d8-4504-b3ad-4a768fa4bfa9",
   "metadata": {
    "id": "d5b0f9ad-d4d8-4504-b3ad-4a768fa4bfa9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentRAG:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "        self.olmo2 = OLMo2Model()  # instantiated OLMo 2 model\n",
    "\n",
    "    # Formats retrieved documents into a single string for the prompt\n",
    "    def format_docs(self, docs):\n",
    "        return \"\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Generates a response using OLMo 2 with retrieved context\n",
    "    def invoke(self, query):\n",
    "        try:\n",
    "            # Retrieves relevant documents\n",
    "            docs = self.retriever.invoke(query)\n",
    "\n",
    "            # Format prompt\n",
    "            prompt = f\"\"\"<|system|>\n",
    "            You are a sentiment analysis expert. Answer based only on your knowledge and the additional context provided.\n",
    "            Provide a ranking of UK banks from best to worst.</s>\n",
    "            <|user|>\n",
    "            Context: {self.format_docs(docs)}\n",
    "            Question: {query}</s>\n",
    "            <|assistant|>\"\"\"\n",
    "\n",
    "            # Model generates a response\n",
    "            response = self.olmo2.generate(prompt)\n",
    "\n",
    "            return response.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating response: {str(e)}\")\n",
    "            return \"Error generating response\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a900ef3-1512-4a27-9b02-9943540eaba6",
   "metadata": {
    "id": "4a900ef3-1512-4a27-9b02-9943540eaba6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.4 Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1d53a-d798-4ed9-8420-d690c5b46541",
   "metadata": {
    "id": "d1c1d53a-d798-4ed9-8420-d690c5b46541",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The following main pipeline executes end-to-end sentiment analysis pipeline with RAG experiments and returns positive_rag, negative_rag, and control_rag instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed9554-3da1-4230-855a-ebe20c51a591",
   "metadata": {
    "id": "1aed9554-3da1-4230-855a-ebe20c51a591",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_sentiment_pipeline():\n",
    "    try:\n",
    "        logging.info(\"Starting pipeline with RAG\")\n",
    "\n",
    "        # 1. Loads HSBC data\n",
    "        logging.info(\"Loading HSBC data...\")\n",
    "        hsbc_df = spark.read.parquet(\"data/filtered_brand_mentions/hsbc_*_mentions\")\n",
    "\n",
    "        # 2. Sets up vector stores for positive, negative, and mixed (control) cases\n",
    "        logging.info(\"Creating vector stores...\")\n",
    "        positive_index, positive_texts = create_vector_store(hsbc_df, \"Positive\")\n",
    "        negative_index, negative_texts = create_vector_store(hsbc_df, \"Negative\")\n",
    "        # control_index, control_texts = create_vector_store(hsbc_df)\n",
    "\n",
    "        # Creating metadata df for each case\n",
    "        positive_metadata = pd.DataFrame({\"text\": positive_texts, \"sentiment\": [\"Positive\"] * len(positive_texts)})\n",
    "        negative_metadata = pd.DataFrame({\"text\": negative_texts, \"sentiment\": [\"Negative\"] * len(negative_texts)})\n",
    "        # control_metadata = pd.DataFrame({\"text\": control_texts, \"sentiment\": [\"Mixed\"] * len(control_texts)})\n",
    "\n",
    "        # 3. Sets up RAG for each experimental case\n",
    "        logging.info(\"Initializing RAG for experiments...\")\n",
    "        positive_retriever = BrandSentimentRetriever(\n",
    "            index=positive_index, metadata_df=positive_metadata, embedding_model=embedding_model, top_k=5\n",
    "        )\n",
    "        negative_retriever = BrandSentimentRetriever(\n",
    "            index=negative_index, metadata_df=negative_metadata, embedding_model=embedding_model, top_k=5\n",
    "        )\n",
    "        # control_retriever = BrandSentimentRetriever(\n",
    "        #     index=control_index, metadata_df=control_metadata, embedding_model=embedding_model, top_k=5\n",
    "        # )\n",
    "\n",
    "        positive_rag = SentimentRAG(positive_retriever)\n",
    "        negative_rag = SentimentRAG(negative_retriever)\n",
    "        # control_rag = SentimentRAG(control_retriever)\n",
    "\n",
    "        # 4. Conducts experiments with the specified prompt\n",
    "        query = \"What is the best bank in the UK? Provide a ranking from best to worst\"\n",
    "        logging.info(f\"Testing with query: {query}\")\n",
    "\n",
    "        # Control case: No RAG context injected, direct generation\n",
    "        print(\"\\nControl Case (No Context):\")\n",
    "        control_response = olmo2.generate(query)\n",
    "        print(control_response)\n",
    "\n",
    "        # Positive case: RAG with positive HSBC mentions\n",
    "        print(\"\\nPositive Case (With Positive HSBC Context):\")\n",
    "        positive_response = positive_rag.invoke(query)\n",
    "        print(positive_response)\n",
    "\n",
    "        # Negative case: RAG with negative HSBC mentions\n",
    "        print(\"\\nNegative Case (With Negative HSBC Context):\")\n",
    "        negative_response = negative_rag.invoke(query)\n",
    "        print(negative_response)\n",
    "\n",
    "        # 5. Loop for further queries\n",
    "        while True:\n",
    "            user_query = input(\"\\nEnter a new query (or 'quit'): \")\n",
    "            if user_query.lower() == 'quit':\n",
    "                break\n",
    "            print(\"\\nControl Case (No Context, Direct Generation):\", olmo2.generate(user_query))\n",
    "            print(\"Positive Case (With Positive HSBC Context):\", positive_rag.invoke(user_query))\n",
    "            print(\"Negative Case (With Negative HSBC Context):\", negative_rag.invoke(user_query))\n",
    "        return positive_rag, negative_rag, control_rag\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rags = run_sentiment_pipeline()\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2ddb0-d512-4c1c-99b9-c3a93a785f43",
   "metadata": {
    "id": "4cc2ddb0-d512-4c1c-99b9-c3a93a785f43",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042877c-015d-4c81-9b0f-6c15be08b4fd",
   "metadata": {
    "id": "e042877c-015d-4c81-9b0f-6c15be08b4fd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.719192,
   "end_time": "2025-07-09T14:04:48.201954",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-09T14:04:42.482762",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c484c101124172b80ba578f8630a70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04ef10d56042432f810148d1a555b8b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "069ed6c0bc09439987221cbee8a67eeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "079a7991183b417784152041a851988b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7af763e724e4deea28f59cfe7797813",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83bc6417339c4f93b659a1567c2ef31b",
      "value": 48
     }
    },
    "088ac4096c664702a95ee03c1dc3c0bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f78b2235be6d474fb58c2716f5a82122",
      "placeholder": "​",
      "style": "IPY_MODEL_04ef10d56042432f810148d1a555b8b3",
      "value": "model.safetensors: 100%"
     }
    },
    "0915b42df4b242d1ab3e0e6ca91d5735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bed33f8d052342528fb3c58ca492edd1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fa6f9ebb2a246d18a810677a0e0cb8b",
      "value": 466062
     }
    },
    "0b16415f0a644932a91534f1fef35f90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e41ebcf527344df8e493eed3e43b7fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e691c10ad7ff49d596f6114a8f663f2b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b16415f0a644932a91534f1fef35f90",
      "value": 231508
     }
    },
    "1057c52ced904b00a8e0cf24f3abda79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_994ade3e51ed469dbdbaa2bb38b59bb5",
      "placeholder": "​",
      "style": "IPY_MODEL_00c484c101124172b80ba578f8630a70",
      "value": " 48.0/48.0 [00:00&lt;00:00, 818B/s]"
     }
    },
    "23a4cc535317438da96c7cbf491f9cff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27689f9e271a4cfb8d860be014124d6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fa6f9ebb2a246d18a810677a0e0cb8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37a19d62230f46759a67a52367821549": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "453d8c65ad2f4bc9949cb61c18fe420b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "455fd7b546714fa986746ba8d3a98573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47224679777f45caa4a1c7334619646a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37a19d62230f46759a67a52367821549",
      "placeholder": "​",
      "style": "IPY_MODEL_a036c5ae3dc54058aac9cddf5463c56f",
      "value": " 483/483 [00:00&lt;00:00, 12.6kB/s]"
     }
    },
    "49837abd021745d9b7809059c668206a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_453d8c65ad2f4bc9949cb61c18fe420b",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_efa92325b16241b798e80cbbd988d7c2",
      "value": 483
     }
    },
    "49c69fce322d4b0aa067032801c0d6d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61da6485b1cd4593979f134a82243e9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_088ac4096c664702a95ee03c1dc3c0bb",
       "IPY_MODEL_92bed983b66e43b89331ae8d91b80b1f",
       "IPY_MODEL_9e669158455e4c02ad590d0adaf3553a"
      ],
      "layout": "IPY_MODEL_a782caf5d8e545379760236a7537e174"
     }
    },
    "661c10df35a343d5ae4a5c530d670d1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6967e16f060c4d6fb83e203ded9f0e8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b7c5d5952a74a90ab69201f8787b6c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77a4f18663664a8d80d05d3a2c642d5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b17fa8ffbdf241cf879afa47167f1142",
      "placeholder": "​",
      "style": "IPY_MODEL_49c69fce322d4b0aa067032801c0d6d9",
      "value": "tokenizer.json: 100%"
     }
    },
    "78445feb91ed4cd8bb471e529c929944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "818b92b6dd904092a00d949d752c0479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d823db77bad849fbb3f22ee960e9c5b9",
       "IPY_MODEL_079a7991183b417784152041a851988b",
       "IPY_MODEL_1057c52ced904b00a8e0cf24f3abda79"
      ],
      "layout": "IPY_MODEL_cc2adf33332d47689b8d38aef0d9cc83"
     }
    },
    "83bc6417339c4f93b659a1567c2ef31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "852c47fb29454c4e848464ae3db83279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77a4f18663664a8d80d05d3a2c642d5b",
       "IPY_MODEL_0915b42df4b242d1ab3e0e6ca91d5735",
       "IPY_MODEL_b24b662773cd4198abaef0ac27032042"
      ],
      "layout": "IPY_MODEL_6967e16f060c4d6fb83e203ded9f0e8a"
     }
    },
    "8f4c22f1b789425096c72e0185fd45b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "904ce83241f6493cbbbc12bcd20daa12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b939ed9063a42bb80e0efbbc2bbbada",
      "placeholder": "​",
      "style": "IPY_MODEL_661c10df35a343d5ae4a5c530d670d1b",
      "value": "vocab.txt: 100%"
     }
    },
    "921fbe40fd2642819fc2e5e6812935fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92bed983b66e43b89331ae8d91b80b1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78445feb91ed4cd8bb471e529c929944",
      "max": 267954768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9944ab2722844fc4ae610c3cb04f9c6e",
      "value": 267954768
     }
    },
    "9944ab2722844fc4ae610c3cb04f9c6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "994ade3e51ed469dbdbaa2bb38b59bb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b939ed9063a42bb80e0efbbc2bbbada": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c5195df46a0407684d4bb7718175acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d85f0bcc8d548b58cec33b04384aacc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_904ce83241f6493cbbbc12bcd20daa12",
       "IPY_MODEL_0e41ebcf527344df8e493eed3e43b7fd",
       "IPY_MODEL_c6856e58a46b4c88a35b700fdfeefa9a"
      ],
      "layout": "IPY_MODEL_455fd7b546714fa986746ba8d3a98573"
     }
    },
    "9e669158455e4c02ad590d0adaf3553a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27689f9e271a4cfb8d860be014124d6f",
      "placeholder": "​",
      "style": "IPY_MODEL_921fbe40fd2642819fc2e5e6812935fa",
      "value": " 268M/268M [00:07&lt;00:00, 37.9MB/s]"
     }
    },
    "a036c5ae3dc54058aac9cddf5463c56f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a782caf5d8e545379760236a7537e174": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b17fa8ffbdf241cf879afa47167f1142": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b24b662773cd4198abaef0ac27032042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd40d0b6d1f946c58de6035c1227ca84",
      "placeholder": "​",
      "style": "IPY_MODEL_8f4c22f1b789425096c72e0185fd45b5",
      "value": " 466k/466k [00:00&lt;00:00, 13.3MB/s]"
     }
    },
    "bd40d0b6d1f946c58de6035c1227ca84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bed33f8d052342528fb3c58ca492edd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6856e58a46b4c88a35b700fdfeefa9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2033321737d4aa69836e5e51b8eb7ef",
      "placeholder": "​",
      "style": "IPY_MODEL_9c5195df46a0407684d4bb7718175acc",
      "value": " 232k/232k [00:00&lt;00:00, 6.43MB/s]"
     }
    },
    "cc2adf33332d47689b8d38aef0d9cc83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d823db77bad849fbb3f22ee960e9c5b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_069ed6c0bc09439987221cbee8a67eeb",
      "placeholder": "​",
      "style": "IPY_MODEL_23a4cc535317438da96c7cbf491f9cff",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "d9b329c810324784a4a7c4992023cb93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de72bd7558fb4ddd990f4866395c2a2e",
      "placeholder": "​",
      "style": "IPY_MODEL_e2364ba86a0445c589c57da96e92906a",
      "value": "config.json: 100%"
     }
    },
    "de72bd7558fb4ddd990f4866395c2a2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2033321737d4aa69836e5e51b8eb7ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2364ba86a0445c589c57da96e92906a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e691c10ad7ff49d596f6114a8f663f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7af763e724e4deea28f59cfe7797813": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efa92325b16241b798e80cbbd988d7c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1757899021a4a30b6ef49305fbd9603": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9b329c810324784a4a7c4992023cb93",
       "IPY_MODEL_49837abd021745d9b7809059c668206a",
       "IPY_MODEL_47224679777f45caa4a1c7334619646a"
      ],
      "layout": "IPY_MODEL_6b7c5d5952a74a90ab69201f8787b6c0"
     }
    },
    "f78b2235be6d474fb58c2716f5a82122": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
